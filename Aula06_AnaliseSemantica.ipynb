{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72b8882c",
      "metadata": {
        "id": "72b8882c"
      },
      "source": [
        "#Aula 06 - Intepretação Semântica e Gramáticas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34b13150",
      "metadata": {
        "id": "34b13150"
      },
      "source": [
        "EX 1 - Representação do significado das palavras e frases com redes Semânticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6aafdbf",
      "metadata": {
        "id": "c6aafdbf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# banco de dados para utilizacao do sinônimos\n",
        "nltk.download('wordnet' )\n",
        "# Corpus que relaciona as palavras em diversos idiomas - traducao automatica\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "sinonimos = wordnet.synsets(\"carro\", lang=\"por\")\n",
        "\n",
        "print(sinonimos)\n",
        "\n",
        "for s in sinonimos:\n",
        "  print(s.lemmas()[0].name())\n",
        "# s.lemmas(): Obtem a lista de lemmas (formas basicas das palavras) no synset atual.\n",
        "# [0]: Pega o primeiro lemma da lista.\n",
        "# .name(): Obtém o nome do lemma (o sinônimo em si).\n",
        "# print(): Imprime o sinônimo na tela."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d9c253",
      "metadata": {
        "id": "98d9c253"
      },
      "source": [
        "representação do significado das palavras e frases por vetores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c8051b",
      "metadata": {
        "id": "b2c8051b"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4571d5",
      "metadata": {
        "id": "0b4571d5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy. load('pt_core_news_md' )\n",
        "\n",
        "palavra1 = nlp('rei')\n",
        "palavra2 = nlp('rainha' )\n",
        "\n",
        "print (palavra1.similarity(palavra2))\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "631d4581",
      "metadata": {
        "id": "631d4581"
      },
      "source": [
        "análise sintática"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc485da9",
      "metadata": {
        "id": "fc485da9"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3833ce51",
      "metadata": {
        "id": "3833ce51"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4515f21",
      "metadata": {
        "id": "e4515f21"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy. load(\"pt_core_news_sm\")\n",
        "frase = \"O cachorro correu no parque.\"\n",
        "doc = nlp(frase)\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bb24dd",
      "metadata": {
        "id": "e9bb24dd"
      },
      "source": [
        "ontologia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2459189f",
      "metadata": {
        "id": "2459189f"
      },
      "outputs": [],
      "source": [
        "!pip install owlready2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f46d44f",
      "metadata": {
        "id": "4f46d44f"
      },
      "outputs": [],
      "source": [
        "\n",
        "from owlready2 import *\n",
        "\n",
        "onto = get_ontology(\"http://exemplo.com/minha_ontologia.owl\")\n",
        "\n",
        "with onto:\n",
        "  class Animal(Thing): pass\n",
        "  class Mamifero(Animal): pass\n",
        "  class Cachorro(Mamifero): pass\n",
        "  class Gato(Mamifero): pass\n",
        "\n",
        "onto.save(\"minha_ontologia.owl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30f0657",
      "metadata": {
        "id": "f30f0657"
      },
      "source": [
        "caso 01 - aplicação de análise semântica em um corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf18bbe",
      "metadata": {
        "id": "cbf18bbe"
      },
      "outputs": [],
      "source": [
        "\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nlp = spacy. load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f5be532",
      "metadata": {
        "id": "4f5be532"
      },
      "outputs": [],
      "source": [
        "\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded A\"\n",
        "\n",
        "doc = nlp(text)\n",
        "syntactic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  syntactic_data.append({\n",
        "    \"Token\": token.text,\n",
        "    \"Pos-Tag\": token.pos_,\n",
        "    \"Dependência\": token.dep_,\n",
        "    \"Cabeça da Dep\": token.head.text\n",
        "  })\n",
        "\n",
        "df_syntactic = pd.DataFrame(syntactic_data)\n",
        "print(\"\\n Análise Sintática:\")\n",
        "print(df_syntactic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2aaa0bf",
      "metadata": {
        "id": "e2aaa0bf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "entities_data = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  entities_data. append({\n",
        "    \"Entidade\": ent.text,\n",
        "    \"Tipo\": ent.label\n",
        "  })\n",
        "\n",
        "df_entities = pd.DataFrame(entities_data)\n",
        "print(\"\\n Reconhecimento de Entidades:\")\n",
        "print(df_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85c3d48",
      "metadata": {
        "id": "c85c3d48"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 3. Análise Semântica com WordNet\n",
        "semantic_data = []\n",
        "\n",
        "for token in doc:\n",
        "  synsets = wn.synsets(token. text)\n",
        "  if synsets:\n",
        "    semantic_data.append({\n",
        "      \"Palavra\": token.text,\n",
        "      \"Significado\": synsets[0].definition(),\n",
        "      \"Exemplo\": synsets[0]. examples ()\n",
        "    })\n",
        "\n",
        "df_semantic = pd.DataFrame(semantic_data)\n",
        "print(\"\\n Análise Semântica:\")\n",
        "print(df_semantic)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}